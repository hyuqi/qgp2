{"cells":[{"cell_type":"markdown","metadata":{"id":"k_Ch3AEZr_HP"},"source":["# Helper Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ff_B0fAhKrND"},"outputs":[],"source":["\"\"\"\n","This module contains all the functions that define the kernels\n","\"\"\"\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","\n","\n","def full_kernel_classic(x, y):\n","    \"\"\"\n","    Classical evaluation of the full kernel\n","    :param x: arg 1\n","    :param y: arg 2\n","    :return:\n","    \"\"\"\n","    k = 1\n","    for i in range(len(x)):\n","        k = k * np.cos(1/2*(x[i]-y[i]))**2\n","    return k\n","\n","\n","def kernel_matrix_classic(X, Y):\n","    \"\"\"\n","    compute the kenel matrix of the full kernel\n","    :param X: vector of samples\n","    :param Y: vector of samples\n","    :return:\n","    \"\"\"\n","    K = np.zeros((len(X), len(Y)))\n","    for i in range(len(X)):\n","        for j in range(len(Y)):\n","            K[i, j] = full_kernel_classic(X[i], Y[j])\n","    return K\n","\n","\n","def kernel_matrix_classic_torch(X, Y):\n","    \"\"\"\n","    compute the kenel matrix of the full kernel potentially utilizing some parallel processing\n","    :param X: vector of samples\n","    :param Y: vector of samples\n","    :return:\n","    \"\"\"\n","    if type(X) is np.ndarray:\n","        X = torch.from_numpy(X)\n","    if type(Y) is np.ndarray:\n","        Y = torch.from_numpy(Y)\n","    # create tensor with entry i x j x k equal to x_ik - y_jk\n","    X = X.unsqueeze(1).expand(-1, Y.size(0), -1)\n","    Y = Y.unsqueeze(0).expand(X.size(0), -1, -1)\n","    K = X - Y\n","    K = torch.cos(K / 2) ** 2\n","    K = torch.prod(K, 2)\n","    return K\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ULe1zRLh8-I"},"outputs":[],"source":["import numpy as np\n","\n","class GaussianProcessRegressor:\n","    \"\"\"\n","    Gaussian Process Regressor for d-dimensional inputs.\n","    Returns both predictive mean and std if requested.\n","    \"\"\"\n","    def __init__(self, kernel, alpha=1e-5):\n","        self.kernel = kernel\n","        self.alpha = alpha\n","        self.X_train = None\n","        self.y_train = None\n","        self.K_inv = None\n","\n","    def fit(self, X, y):\n","        X = np.array(X)\n","        y = np.array(y)\n","        self.X_train = X\n","        self.y_train = y\n","        K = self.kernel(X, X)\n","        K += self.alpha * np.eye(len(X))\n","        self.K_inv = np.linalg.inv(K)\n","\n","    def predict(self, X_test, return_std=False):\n","\n","        X_test = np.array(X_test)\n","        K_star = self.kernel(X_test, self.X_train)\n","        y_mean = K_star @ (self.K_inv @ self.y_train)\n","\n","        if return_std:\n","            K_star_star = self.kernel(X_test, X_test)\n","            cov = K_star_star - K_star @ self.K_inv @ K_star.T\n","            var = np.diag(cov)\n","            var = np.maximum(var, 0.0)\n","            y_std = np.sqrt(var)\n","            return y_mean, y_std\n","        else:\n","            return y_mean\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6EkvzaE6bmOU"},"outputs":[],"source":["from itertools import product\n","\n","# def build_grid(bounds, n_grid):\n","#     \"\"\"\n","#     Build a uniform grid of points within the given 'bounds'.\n","\n","#     Parameters\n","#     ----------\n","#     bounds : list of (low, high) for each dimension (length d)\n","#     n_grid : int\n","#         Number of grid points per dimension.\n","\n","#     Returns\n","#     -------\n","#     X_grid : np.ndarray of shape (n_grid^d, d)\n","#         All points in the grid.\n","#     \"\"\"\n","#     # For each dimension, create an array of n_grid points from low to high\n","#     axes = [np.linspace(low, high, n_grid) for (low, high) in bounds]\n","#     # Cartesian product of all axes\n","#     # e.g. for d=2, we get all pairs (x,y); for d=3, all (x,y,z), etc.\n","#     mesh = list(product(*axes))  # a list of d-tuples\n","#     return np.array(mesh)\n","\n","def build_grid(bounds, n_grid, random_state=None):\n","    \"\"\"\n","    Draw n_grid^d random points uniformly from the given 'bounds'.\n","\n","    Parameters\n","    ----------\n","    bounds : list of (low, high) for each dimension (length d)\n","        Defines a d-dimensional box in which to sample points.\n","    n_grid : int\n","        We will create exactly n_grid^d random points in total.\n","    random_state : int or None\n","        Optional seed for reproducibility.\n","\n","    Returns\n","    -------\n","    X_rand : np.ndarray of shape (n_grid^d, d)\n","        The random points in the domain.\n","    \"\"\"\n","    np.random.seed(None)\n","\n","    d = len(bounds)\n","    n_points = n_grid ** d  # total number of random points\n","    X_rand = np.zeros((n_points, d))\n","\n","    for i in range(n_points):\n","        for j in range(d):\n","            low, high = bounds[j]\n","            X_rand[i, j] = np.random.uniform(low, high)\n","\n","    return X_rand\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zUirsK3YG8nr"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from itertools import product\n","from scipy.stats import norm\n","\n","\n","\n","def gp_ucb_nd(\n","    f,                 # black-box reward function, shape: (n, d) -> (n,)\n","    gp,                # a GaussianProcessRegressor instance (fit, predict)\n","    bounds,            # list of (low, high) for each dimension\n","    n_iter=10,         # number of UCB iterations\n","    init_points=3,     # number of initial random samples\n","    n_grid=50,         # number of grid points per dimension to search for UCB max\n","    beta_func=None,    # a callable or None => we define a default\n","    random_state=None,\n","    error = 1,\n","    verbose=False\n","):\n","    \"\"\"\n","    Runs GP-UCB for a multi-armed bandit / Bayesian optimization problem.\n","\n","    Parameters\n","    ----------\n","    f : callable\n","        The unknown reward function (black-box).\n","        Input shape (n, d) -> (n,) for n points in dimension d.\n","    gp : GaussianProcessRegressor\n","        Surrogate GP model implementing:\n","          - gp.fit(X, y)\n","          - gp.predict(X, return_std=True) -> (mean, std)\n","    bounds : list of (low, high)\n","        Domain bounding box in d dimensions.\n","    n_iter : int\n","        Number of GP-UCB rounds.\n","    init_points : int\n","        How many random points to sample initially.\n","    n_grid : int\n","        Grid resolution for selecting x_t = argmax_x [mu_{t-1}(x) + sqrt(beta_t)*sigma_{t-1}(x)].\n","    beta_func : callable or None\n","        If None, we define a simple default that grows with t.  Otherwise,\n","        something like:  beta_func(t) -> float\n","    random_state : int or None\n","        For reproducibility.\n","    verbose : bool\n","        Print iteration details if True.\n","\n","    Returns\n","    -------\n","    regrets : ndarray of shape (n_iter + init_points,)\n","        Cumulative regret at each iteration (the sum over t=1..T of [f(x*) - f(x_t)]).\n","    X_samples : ndarray of shape (n_iter + init_points, d)\n","    Y_samples : ndarray of shape (n_iter + init_points,)\n","\n","    Notes\n","    -----\n","    - We assume we can approximate the global max f(x*) by a dense grid search\n","      once, for regret calculation.  In a real bandit scenario, you might not\n","      know x*, but for synthetic tests or known benchmark functions, we do.\n","    - The domain is searched by a grid of size (n_grid^d).  This is only feasible\n","      for small d or moderate n_grid.\n","    \"\"\"\n","\n","    if random_state is not None:\n","        np.random.seed(random_state)\n","\n","    d = len(bounds)\n","\n","    # 1) Create a dense grid to:\n","    #    - approximate x* (the global maximizer)\n","    #    - search for the UCB argmax each iteration\n","    X_grid = build_grid(bounds, n_grid=n_grid)  # shape (n_grid^d, d)\n","\n","    # 2) (Optional) approximate the global maximum for regret calculation\n","    #    We take the best among the same grid points to get x_star\n","    Y_grid = f(X_grid)\n","    idx_best = np.argmax(Y_grid)\n","    x_star = X_grid[idx_best]\n","    f_star = Y_grid[idx_best]  # approximate global max value\n","\n","    # 3) Helper to define a default beta_t if user didn't supply one\n","    if beta_func is None:\n","        # E.g. a common choice for finite domain or small bounding\n","        # can be something like: 2 ln(t^2 * pi^2 / (6 delta))\n","        # but we just do a simpler scaling of log t for demonstration.\n","        def beta_func(t):\n","            return 2.0 * np.log(1000 * t**2 * 10 / 6 / 0.1 )   # delta = 0.1\n","    # else user supplies something like beta_func(t) => some formula\n","\n","    # 4) Initialize data by sampling 'init_points' random points\n","    def sample_random(n):\n","        return np.array([\n","            [np.random.uniform(low, high) for (low, high) in bounds]\n","            for _ in range(n)\n","        ])\n","\n","    X_samples = sample_random(init_points)  # shape (init_points, d)\n","    Y_samples = f(X_samples)               # shape (init_points,)\n","\n","    # 5) We'll keep track of cumulative regrets\n","    regrets = np.zeros(n_iter + init_points)\n","    # First 'init_points' regrets are computed from those random picks\n","    # Evaluate the regret at each step\n","    cum_regret = 0.0\n","    for i in range(init_points):\n","        cum_regret += (f_star - Y_samples[i])\n","        regrets[i] = cum_regret\n","\n","    # 6) Main loop of GP-UCB\n","    log_sum_for_beta = 0\n","    for step in range(n_iter):\n","\n","        X_grid = build_grid(bounds, n_grid=n_grid)\n","\n","        t = init_points + step + 1  # total iteration index (1-based)\n","\n","        # Fit GP on current data\n","        gp.fit(X_samples, Y_samples)\n","\n","        # Compute mean & std on the entire grid\n","        mu_grid, std_grid = gp.predict(X_grid, return_std=True)\n","\n","        # Define current beta_t\n","        beta_t = 0.1 * (2*np.log(20)+log_sum_for_beta) ** 0.5 + 3\n","\n","        #beta_func(t)\n","\n","        # UCB = mu + sqrt(beta_t) * std\n","        ucb_values = mu_grid + (beta_t + error * np.sqrt(t) ) * std_grid\n","\n","        # if step % 10 == 0:\n","        #   print(step)\n","        #   print(mu_grid[:10], std_grid[:10])\n","        #   print(ucb_values[:10])\n","        #   #print(np.max(ucb_values))\n","        #   print(\"==========\")\n","\n","        # Argmax on the grid\n","        idx_next = np.argmax(ucb_values)\n","        x_next = X_grid[idx_next].reshape(1, -1)\n","\n","        log_sum_for_beta += np.log(1 + std_grid[idx_next])\n","\n","        #print(beta_t + error * np.sqrt(t) )\n","        #print(std_grid[idx_next])\n","\n","        # Evaluate the unknown function f (bandit feedback)\n","        np.random.seed(None)\n","        noise = np.random.normal(0, 0.1)\n","        y_true = f(x_next)\n","        y_next = y_true + noise\n","        #print(noise)\n","\n","        # Update data\n","        X_samples = np.vstack([X_samples, x_next])\n","        Y_samples = np.concatenate([Y_samples, y_next])\n","\n","        # Update cumulative regret\n","        cum_regret += (f_star - y_true[0])\n","        regrets[init_points + step] = cum_regret\n","\n","        if verbose:\n","            print(f\"Iteration {step+1}/{n_iter}, t={t}, beta={beta_t:.3f}, \"\n","                  f\"x_next={x_next[0]}, f(x)={y_next[0]:.4f}, UCB={ucb_values[idx_next]:.4f}, \"\n","                  f\"CumReg={cum_regret:.4f}\")\n","\n","    return regrets, X_samples, Y_samples\n","\n","\n","\n","\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import trange\n","\n","def run_multiple_experiments_gp_ucb(\n","    f,\n","    gp,\n","    bounds,\n","    n_runs=5,\n","    n_iter=10,\n","    init_points=3,\n","    n_grid=50,\n","    beta_func=None,\n","    random_state=None,\n","    error = 1,\n","    verbose=False\n","):\n","    \"\"\"\n","    Runs the GP-UCB experiment 'n_runs' times, each time creating a new GP instance.\n","    Returns the average cumulative regret across runs.\n","\n","    Parameters\n","    ----------\n","    f : callable\n","        The black-box reward function.\n","    gp_class_factory : callable\n","        A function that, when called, returns a *new* untrained GaussianProcessRegressor\n","        (or similar). For example:\n","          lambda: GaussianProcessRegressor(kernel=RBF(...), alpha=..., optimizer=None)\n","        We need a fresh GP for each run, so that each run is independent.\n","    bounds : list of (low, high)\n","        Domain bounding box.\n","    n_runs : int\n","        Number of independent runs to average over.\n","    n_iter : int\n","        Number of GP-UCB rounds (not counting the init_points).\n","    init_points : int\n","        Number of random initial points in each run.\n","    n_grid : int\n","        Grid resolution for argmax search in each run.\n","    beta_func : callable or None\n","        If None, use a default log-based. Otherwise a function beta_func(t) -> float.\n","    random_state : int or None\n","        For reproducibility. If set, seeds the first run's RNG, then subsequent runs\n","        will shift the seed.\n","    verbose : bool\n","        Whether to print details for each run.\n","\n","    Returns\n","    -------\n","    avg_regret : ndarray of shape (n_iter + init_points,)\n","        The pointwise average of the cumulative regret across runs.\n","    regrets_all : ndarray of shape (n_runs, n_iter + init_points)\n","        The individual run's cumulative-regret curves.\n","    \"\"\"\n","\n","    from copy import deepcopy\n","\n","    # If we want reproducibility, set base seed\n","    base_seed = random_state if random_state is not None else None\n","\n","    # We'll store the regret curve for each run here\n","    regrets_all = []\n","\n","    for i in trange(n_runs, desc=\"GP-UCB Experiments\"):\n","        # For each run, optionally shift the seed\n","        if base_seed is not None:\n","            # shift by i to get distinct seeds\n","            np.random.seed(base_seed + i)\n","\n","        # Create a fresh GP instance\n","        gp_model = gp\n","\n","        # Import or copy the gp_ucb_nd from your previous code snippet:\n","        regrets, X_samples, Y_samples = gp_ucb_nd(\n","            f=f,\n","            gp=gp_model,\n","            bounds=bounds,\n","            n_iter=n_iter,\n","            init_points=init_points,\n","            n_grid=n_grid,\n","            beta_func=beta_func,\n","            random_state=None,  # we've set the seed externally\n","            error = error,\n","            verbose=(verbose and i == 0)  # only verbose in the 1st run, e.g.\n","        )\n","\n","        regrets_all.append(regrets)\n","\n","    regrets_all = np.array(regrets_all)  # shape (n_runs, n_steps)\n","    avg_regret = regrets_all.mean(axis=0)\n","    std_regret = regrets_all.std(axis=0)\n","    return avg_regret, regrets_all, std_regret\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GwQLCcYwLbuj"},"outputs":[],"source":["lst_of_c = np.array([1/8, 1/8,1/8,1/8,1/8,1/8,1/8,\n","          1/16,1/16,1/16,1/16,1/16,1/16,1/16,1/16,1/16,1/16,1/16,1/16,\n","          1/32,1/32,1/32,1/32,1/32,1/32,1/32,1/32,\n","          ])\n","lst_of_sqrt_c = lst_of_c**0.5\n","\n","# lst_of_features = [lambda d0,d1,d2: np.cos(d0)/8, lambda d0,d1,d2:np.cos(d1)/8, lambda d0,d1,d2:np.cos(d2)/8,\n","#             lambda d0,d1,d2:np.cos(d0+d1)/16, lambda d0,d1,d2:np.cos(d0+d2)/16, lambda d0,d1,d2:np.cos(d1+d2)/16,\n","#             lambda d0,d1,d2:np.cos(d0-d1)/16, lambda d0,d1,d2:np.cos(d0-d2)/16, lambda d0,d1,d2:np.cos(d1-d2)/16,\n","#             lambda d0,d1,d2:np.cos(d0+d1+d2)/32, lambda d0,d1,d2:np.cos(d0+d1-d2)/32, lambda d0,d1,d2:np.cos(d0-d1+d2)/32, lambda d0,d1,d2:np.cos(d0-d1-d2)/32\n","#           ]\n","\n","def feature_map_full(x):\n","    \"\"\"\n","    X: shape (N, 2) where each row is [x1, x2].\n","\n","    Returns: Phi, shape (N, 5),\n","             where Phi[i, :] = [1, cos(x1), sin(x1), cos(x2), sin(x2)] for the i-th sample.\n","    \"\"\"\n","    x0,x1,x2 = x[0],x[1],x[2]\n","    u0,u1,u2,u3 = 1/8,1/8,1/16,1/32\n","\n","    return np.array([\n","        u0**0.5 * 1,\n","\n","        u1**0.5 * np.cos(x0), u1**0.5 * np.sin(x0),\n","        u1**0.5 * np.cos(x1), u1**0.5 * np.sin(x1),\n","        u1**0.5 * np.cos(x2), u1**0.5 * np.sin(x2),\n","\n","        u2**0.5 * np.cos(x0+x1), u2**0.5 * np.sin(x0+x1), u2**0.5 * np.cos(x0-x1), u2**0.5 * np.sin(x0-x1),\n","        u2**0.5 * np.cos(x0+x2), u2**0.5 * np.sin(x0+x2), u2**0.5 * np.cos(x0-x2), u2**0.5 * np.sin(x0-x2),\n","        u2**0.5 * np.cos(x1+x2), u2**0.5 * np.sin(x1+x2), u2**0.5 * np.cos(x1-x2), u2**0.5 * np.sin(x1-x2),\n","\n","        u3**0.5 * np.cos(x0+x1+x2), u3**0.5 * np.sin(x0+x1+x2),\n","        u3**0.5 * np.cos(x0+x1-x2), u3**0.5 * np.sin(x0+x1-x2),\n","        u3**0.5 * np.cos(x0-x1+x2), u3**0.5 * np.sin(x0-x1+x2),\n","        u3**0.5 * np.cos(x0-x1-x2), u3**0.5 * np.sin(x0-x1-x2)\n","    ])\n","\n","\n","def reduced_kernel_classic(x, y, dim=27,seed=None):\n","    \"\"\"\n","    Classical evaluation of the full kernel\n","    :param x: arg 1\n","    :param y: arg 2\n","    :return:\n","    \"\"\"\n","    x_feats = feature_map_full(x)[:dim]\n","    y_feats = feature_map_full(y)[:dim]\n","\n","    return np.sum(x_feats * y_feats)\n","\n","\n","def reduced_matrix_classic(X, Y, dim=27):\n","    \"\"\"\n","    compute the kenel matrix of the full kernel\n","    :param X: vector of samples\n","    :param Y: vector of samples\n","    :return:\n","    \"\"\"\n","    #print(dim)\n","\n","    K = np.zeros((len(X), len(Y)))\n","    for i in range(len(X)):\n","        for j in range(len(Y)):\n","            K[i, j] = reduced_kernel_classic(X[i], Y[j],dim)\n","    return K"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"ehDK46gjM89W"},"outputs":[],"source":["bounds = [(0, 2*np.pi), (0, 2*np.pi),(0, 2*np.pi)]\n","X_grid = build_grid(bounds, n_grid=3)\n","for i in range(1,28,2):\n","  print(i)\n","  print(kernel_matrix_classic(X_grid,X_grid)[0,0] - reduced_matrix_classic(X_grid,X_grid,i)[0,0])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MEdjnpJkVWDr"},"outputs":[],"source":["\n","sigma_w = 0.5\n","w_random = np.random.normal(loc=0.0, scale=sigma_w, size=27)\n","#w_random = np.array([1,1,1,1,1,1,1,1,1])\n","#w_random[7],w_random[8] = 1,1\n","print(w_random)\n","\n","def f_draw_from_GP(x):\n","    \"\"\"A random draw from the GP prior with feature map phi, weights ~ N(0, sigma^2 I).\"\"\"\n","    Phi = feature_map_full(x)\n","    return np.sum(Phi * w_random)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZTlDa3qYW3GI"},"outputs":[],"source":["x = [0,0.44,-1]\n","y = [-3,2,0.3]\n","full_kernel_classic(x,y)\n","\n","sum(feature_map_full(x) * feature_map_full(y))\n","w_random = np.random.normal(loc=0.0, scale=sigma_w, size=27)\n","f_draw_from_GP(x)"]},{"cell_type":"markdown","metadata":{"id":"eE07bhiyPtnN"},"source":["# repeat for different kernel dimension"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0yNpB4ujKsGY"},"outputs":[],"source":["w_random = np.array([1 for _ in range(27)])\n","w_random = np.random.normal(loc=0.0, scale=sigma_w, size=27)\n","\n","qubits = 3\n","seed = 1\n","bounds = [(0, 2*np.pi), (0, 2*np.pi),(0, 2*np.pi)]\n","\n","quantum_f = lambda X: np.array([f_draw_from_GP(X[i]) for i in range(X.shape[0])])\n","\n","\n","dim_tried = []\n","regret_for_dim = []\n","std_regret_for_dim = []\n","\n","for dim in trange(1,28,1, desc=\"Dimension of Kernel Used\"):\n","\n","  kernell = lambda X,Y: reduced_matrix_classic(X,Y,dim=dim)\n","\n","  gp = GaussianProcessRegressor(kernel=kernell, alpha=1e-4)\n","\n","  avg_best, best_hist_all,std_regret = run_multiple_experiments_gp_ucb(\n","  f=quantum_f,\n","  gp=gp,\n","  bounds=bounds,\n","  n_runs=30,\n","  n_iter=100,\n","  init_points=1,\n","  n_grid=10,\n","  beta_func=None,  # use the default inside gp_ucb_nd\n","  random_state=42,\n","  error = 6/dim,#get_max_error(dim),\n","  verbose=False\n",")\n","\n","  dim_tried.append(dim)\n","  regret_for_dim.append(avg_best[-1]/6)\n","  std_regret_for_dim.append(std_regret[-1]/6)\n","  print(avg_best)\n","\n","\n","plt.errorbar(dim_tried,regret_for_dim,std_regret_for_dim,ls=\"-\",\n","             marker='d',\n","             color=\"#009E73\",\n","             alpha=1.0,\n","             capsize=4)\n","plt.title(\"Regret for Different Kernel Used\")\n","plt.xlabel(\"Dimension of Kernel Used for Modeling\")\n","plt.ylabel(\"Regret for T=100\")\n","plt.grid(True)\n","plt.legend()\n","plt.show()\n","\n","\n","print(regret_for_dim)\n","print(std_regret_for_dim)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kexeEKmZsjlk"},"outputs":[],"source":["pip install pennylane"]},{"cell_type":"markdown","metadata":{"id":"Xe15VI0eXqSk"},"source":["# GP"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QrfrrgdV0s4C"},"outputs":[],"source":["################################################################################\n","# Quantum-Kernel-based BO for a 3-Qubit PennyLane Circuit Minimizing Ising Energy\n","################################################################################\n","\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","from functools import lru_cache\n","from scipy.special import erf\n","\n","import pennylane as qml\n","from pennylane import numpy as pnp\n","\n","##############################################################################\n","# 1) The Provided GaussianProcessRegressor Class (from your prompt)\n","##############################################################################\n","class GaussianProcessRegressor:\n","    \"\"\"\n","    Gaussian Process Regressor for d-dimensional inputs.\n","    Returns both predictive mean and std if requested.\n","    \"\"\"\n","    def __init__(self, kernel, alpha=1e-5):\n","        self.kernel = kernel\n","        self.alpha = alpha\n","        self.X_train = None\n","        self.y_train = None\n","        self.K_inv = None\n","\n","    def fit(self, X, y):\n","        X = np.array(X)\n","        y = np.array(y)\n","        self.X_train = X\n","        self.y_train = y\n","        K = self.kernel(X, X)\n","        K += self.alpha * np.eye(len(X))\n","        self.K_inv = np.linalg.inv(K)\n","\n","    def predict(self, X_test, return_std=False):\n","        X_test = np.array(X_test)\n","        K_star = self.kernel(X_test, self.X_train)\n","        y_mean = K_star @ (self.K_inv @ self.y_train)\n","\n","        if return_std:\n","            K_star_star = self.kernel(X_test, X_test)\n","            cov = K_star_star - K_star @ self.K_inv @ K_star.T\n","            var = np.diag(cov)\n","            var = np.maximum(var, 0.0)\n","            y_std = np.sqrt(var)\n","            return y_mean, y_std\n","        else:\n","            return y_mean\n","\n","##############################################################################\n","# 2) Define the 3-qubit circuit & Hamiltonian for Ising-like model\n","##############################################################################\n","num_qubits = 3\n","num_layers = 1\n","dev = qml.device(\"default.qubit\", wires=num_qubits, shots=None)\n","\n","# We'll define an Ising Hamiltonian with effectively + X_jX_{j+1} + Z_j\n","# by setting Jx=-1, hz=-1 in the \"paper's sign\" => sum_j X_jX_j+1 + sum_j Z_j\n","# We'll just build a PennyLane Hamiltonian similarly:\n","obs = []\n","coeffs = []\n","\n","# Coupling: X_j X_{j+1}\n","for j in range(num_qubits - 1):\n","    obs.append(qml.PauliX(j) @ qml.PauliX(j+1))\n","    coeffs.append(1.0)  # effectively +1\n","\n","# Local Z\n","for j in range(num_qubits):\n","    obs.append(qml.PauliZ(j))\n","    coeffs.append(1.0)\n","\n","H = qml.Hamiltonian(coeffs, obs)\n","\n","# dimension => (2 + 2*num_layers)*num_qubits => (2+2*3)*3 => 24\n","D = (2 + 2*num_layers)*num_qubits\n","\n","@qml.qnode(dev)\n","def circuit_energy(params_flat):\n","    \"\"\"\n","    PennyLane QNode that prepares the 3-qubit, 3-layer circuit (24 params),\n","    then measures the expectation of H.\n","    \"\"\"\n","    params_reshaped = params_flat.reshape((2*(num_layers+1), num_qubits))  # shape (8,3)\n","    # 1) initial block\n","    for q in range(num_qubits):\n","        qml.RY(params_reshaped[0,q], wires=q)\n","        qml.RZ(params_reshaped[1,q], wires=q)\n","\n","    # 2) repeated layers\n","    idx=2\n","    for _layer in range(num_layers):\n","        # entangle\n","        qml.CNOT(wires=[0,1])\n","        qml.CNOT(wires=[0,2])\n","        qml.CNOT(wires=[1,2])\n","        # single-qubit\n","        for q in range(num_qubits):\n","            qml.RY(params_reshaped[idx,q], wires=q)\n","            qml.RZ(params_reshaped[idx+1,q], wires=q)\n","        idx+=2\n","\n","    return qml.expval(H)\n","\n","def cost_fn(params_flat):\n","    return float(circuit_energy(params_flat))\n","\n","##############################################################################\n","# 3) Build a \"quantum fidelity kernel\" => overlap of states\n","##############################################################################\n","# We'll define a QNode that returns state, then compute fidelity = |<psi(x)|psi(y)>|^2\n","# For efficiency, store states in a cache so we don't recalc them repeatedly.\n","\n","@qml.qnode(dev)\n","def circuit_state(params_flat):\n","    \"\"\"\n","    Returns the state vector (1D complex array) from the same circuit,\n","    so we can compute fidelity.\n","    \"\"\"\n","    params_reshaped = params_flat.reshape((2*(num_layers+1), num_qubits))\n","    # same structure as above\n","    for q in range(num_qubits):\n","        qml.RY(params_reshaped[0,q], wires=q)\n","        qml.RZ(params_reshaped[1,q], wires=q)\n","    idx=2\n","    for _layer in range(num_layers):\n","        qml.CNOT(wires=[0,1])\n","        qml.CNOT(wires=[0,2])\n","        qml.CNOT(wires=[1,2])\n","        for q in range(num_qubits):\n","            qml.RY(params_reshaped[idx,q], wires=q)\n","            qml.RZ(params_reshaped[idx+1,q], wires=q)\n","        idx+=2\n","    return qml.state()\n","\n","# We'll store states in an LRU cache for fast repeated calls\n","@lru_cache(None)\n","def get_state(params_tuple):\n","    \"\"\"\n","    params_tuple is a tuple of 24 floats. We'll convert to a pnp.array and run circuit_state.\n","    We store the result in a cache for speed.\n","    \"\"\"\n","    arr = pnp.array(params_tuple, dtype=pnp.float64)\n","    return circuit_state(arr)\n","\n","def quantum_fidelity_kernel(X, Y):\n","    \"\"\"\n","    For each pair (x_i, y_j) in X, Y, compute fidelity = |<psi(x_i)|psi(y_j)>|^2\n","    X => NxD, Y => MxD\n","    We'll do NxM result.\n","    We'll store states in a dictionary to avoid repeated circuit calls.\n","    \"\"\"\n","    X = np.atleast_2d(X)\n","    Y = np.atleast_2d(Y)\n","    N, D_ = X.shape\n","    M, D2_ = Y.shape\n","    assert D_==D2_, \"Dimension mismatch\"\n","    K = np.zeros((N,M), dtype=float)\n","    for i in range(N):\n","        # convert X[i] to tuple\n","        xi_tuple = tuple(X[i])\n","        psi_i = get_state(xi_tuple)  # 2^3=8 dim complex array\n","        # we only do conj once\n","        conj_psi_i = np.conjugate(psi_i)\n","        for j in range(M):\n","            yj_tuple = tuple(Y[j])\n","            psi_j = get_state(yj_tuple)\n","            overlap = np.vdot(psi_i, psi_j)  # or conj_psi_i @ psi_j\n","            # fidelity\n","            val = abs(overlap)**2\n","            K[i,j] = val\n","    return K\n","\n","##############################################################################\n","# 4) Simple BO approach with this quantum kernel GP\n","##############################################################################\n","def expected_improvement(X_star, f_best, gp):\n","    \"\"\"\n","    Standard EI => for each x in X_star, compute:\n","      mu, std => z=(f_best - mu)/std\n","      pdf, cdf => improvement = (f_best - mu)*cdf + std*pdf\n","    We pick the argmax.\n","    \"\"\"\n","    mu, std = gp.predict(X_star, return_std=True)\n","    ei = np.zeros_like(mu)\n","    mask = std>1e-12\n","    z = (f_best - mu[mask]) / std[mask]\n","    pdf = 1./np.sqrt(2.*math.pi)*np.exp(-0.5*z**2)\n","    cdf = 0.5*(1.+erf(z/np.sqrt(2.)))\n","    improvement = (f_best - mu[mask])*cdf + std[mask]*pdf\n","    improvement = np.maximum(improvement, 0.)\n","    ei[mask] = improvement\n","\n","    ei = -(mu - 2*std)\n","    return ei\n","\n","def quantum_kernel_bo(n_init=5, n_iter=20, seed=0, n_cand=1000):\n","    np.random.seed(seed)\n","    # dimension is 24\n","    # 1) gather initial data\n","    X_data = np.random.rand(n_init, D)*2.*math.pi\n","    y_data = np.array([cost_fn(row) for row in X_data])\n","\n","    # 2) build GP with quantum_fidelity_kernel\n","    gp = GaussianProcessRegressor(kernel=quantum_fidelity_kernel, alpha=1e-9)\n","    gp.fit(X_data, y_data)\n","\n","    best_history = [y_data.min()]\n","\n","    for step in range(n_iter):\n","        # 3) find next candidate x via EI over random set\n","        f_best = y_data.min()\n","        X_cand = np.random.rand(n_cand, D)*2.*math.pi\n","        ei_vals = expected_improvement(X_cand, f_best, gp)\n","        idx_best = np.argmax(ei_vals)\n","        x_next = X_cand[idx_best]\n","        y_next = cost_fn(x_next)\n","        # 4) update training data\n","        X_data = np.vstack([X_data, x_next])\n","        y_data = np.concatenate([y_data, [y_next]])\n","        gp.fit(X_data, y_data)\n","        best_so_far = min(best_history[-1], y_next)\n","        best_history.append(best_so_far)\n","\n","        print(f\"Iteration {step+1:2d}, best so far = {best_so_far:.6f}\")\n","\n","    return X_data, y_data, best_history\n","\n","##############################################################################\n","# 5) Run it\n","##############################################################################\n","if __name__==\"__main__\":\n","    X_data, y_data, best_hist = quantum_kernel_bo(n_init=5, n_iter=100, seed=None, n_cand=200)\n","    print(\"Final best energy found:\", best_hist[-1])\n","    plt.plot(best_hist, label=\"Best energy so far\")\n","    plt.xlabel(\"Iteration\")\n","    plt.ylabel(\"Energy\")\n","    plt.title(\"BO with Quantum Fidelity Kernel (3-Qubit Ising, 24 params)\")\n","    plt.legend()\n","    plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"YyOY0c3dmn0L"},"source":["## projected kernels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fsTBJbX2acgN"},"outputs":[],"source":["##############################################################################\n","# 1) Imports & Setup\n","##############################################################################\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","from functools import lru_cache\n","from scipy.special import erf\n","\n","import pennylane as qml\n","from pennylane import numpy as pnp\n","\n","##############################################################################\n","# 2) GaussianProcessRegressor (unchanged from your prompt)\n","##############################################################################\n","class GaussianProcessRegressor:\n","    \"\"\"\n","    Gaussian Process Regressor for d-dimensional inputs.\n","    Returns both predictive mean and std if requested.\n","    \"\"\"\n","    def __init__(self, kernel, alpha=1e-5):\n","        self.kernel = kernel\n","        self.alpha = alpha\n","        self.X_train = None\n","        self.y_train = None\n","        self.K_inv = None\n","\n","    def fit(self, X, y):\n","        X = np.array(X)\n","        y = np.array(y)\n","        self.X_train = X\n","        self.y_train = y\n","        K = self.kernel(X, X)\n","        K += self.alpha * np.eye(len(X))\n","        self.K_inv = np.linalg.inv(K)\n","\n","    def predict(self, X_test, return_std=False):\n","        X_test = np.array(X_test)\n","        K_star = self.kernel(X_test, self.X_train)\n","        y_mean = K_star @ (self.K_inv @ self.y_train)\n","\n","        if return_std:\n","            K_star_star = self.kernel(X_test, X_test)\n","            cov = K_star_star - K_star @ self.K_inv @ K_star.T\n","            var = np.diag(cov)\n","            var = np.maximum(var, 0.0)\n","            y_std = np.sqrt(var)\n","            return y_mean, y_std\n","        else:\n","            return y_mean\n","\n","##############################################################################\n","# 3) Setup: 3-qubit circuit, Ising Hamiltonian, cost function\n","##############################################################################\n","num_qubits = 3\n","num_layers = 1\n","dev = qml.device(\"default.qubit\", wires=num_qubits, shots=None)\n","\n","# Build H = sum_j X_jX_{j+1} + sum_j Z_j\n","obs = []\n","coeffs = []\n","for j in range(num_qubits-1):\n","    obs.append(qml.PauliX(j) @ qml.PauliX(j+1))\n","    coeffs.append(1.0)\n","for j in range(num_qubits):\n","    obs.append(qml.PauliZ(j))\n","    coeffs.append(1.0)\n","H = qml.Hamiltonian(coeffs, obs)\n","\n","# dimension => (2 + 2*num_layers)*num_qubits => 24 if num_layers=3,\n","# but here we set num_layers=1 for a simpler example => (2+2*1)*3=6 parameters\n","D = (2 + 2*num_layers)*num_qubits\n","\n","@qml.qnode(dev)\n","def circuit_energy(params_flat):\n","    \"\"\"\n","    Prepare the circuit (with 'num_layers'=1) and measure expectation of H.\n","    \"\"\"\n","    params_reshaped = params_flat.reshape((2*(num_layers+1), num_qubits))\n","    # 1) initial block\n","    for q in range(num_qubits):\n","        qml.RY(params_reshaped[0,q], wires=q)\n","        qml.RZ(params_reshaped[1,q], wires=q)\n","    idx=2\n","    # repeated layers\n","    for _layer in range(num_layers):\n","        qml.CNOT(wires=[0,1])\n","        qml.CNOT(wires=[0,2])\n","        qml.CNOT(wires=[1,2])\n","        for q in range(num_qubits):\n","            qml.RY(params_reshaped[idx,q], wires=q)\n","            qml.RZ(params_reshaped[idx+1,q], wires=q)\n","        idx+=2\n","    return qml.expval(H)\n","\n","def cost_fn(params_flat):\n","    return float(circuit_energy(params_flat))\n","\n","##############################################################################\n","# 4) Partial-Density QNode => measure subset of qubits' density matrix\n","##############################################################################\n","# We'll specify `subset_wires` as a list of qubit indices. Then we do\n","# qml.density_matrix(subset_wires). This returns a 2^(|subset|) x 2^(|subset|) complex matrix,\n","# which might be mixed if the global state is partially traced out.\n","\n","@qml.qnode(dev)\n","def circuit_partial_density(params_flat, subset_wires):\n","    \"\"\"\n","    Returns the partial density matrix for a specified subset of qubits.\n","    The rest are traced out automatically by PennyLane.\n","    \"\"\"\n","    # same circuit as above\n","    params_reshaped = params_flat.reshape((2*(num_layers+1), num_qubits))\n","    # initial\n","    for q in range(num_qubits):\n","        qml.RY(params_reshaped[0,q], wires=q)\n","        qml.RZ(params_reshaped[1,q], wires=q)\n","    idx=2\n","    for _layer in range(num_layers):\n","        qml.CNOT(wires=[0,1])\n","        qml.CNOT(wires=[0,2])\n","        qml.CNOT(wires=[1,2])\n","        for q in range(num_qubits):\n","            qml.RY(params_reshaped[idx,q], wires=q)\n","            qml.RZ(params_reshaped[idx+1,q], wires=q)\n","        idx+=2\n","\n","    return qml.density_matrix(wires=subset_wires)\n","\n","@lru_cache(None)\n","def get_partial_density(params_tuple, subset_wires_tuple):\n","    \"\"\"\n","    Cache for partial density matrix.\n","    PennyLane expects a python list for `wires=...`,\n","    but we can't store a list as a cache key, so we use a tuple of int.\n","    \"\"\"\n","    arr = pnp.array(params_tuple, dtype=pnp.float64)\n","    # convert subset_wires_tuple back to a list\n","    wires_list = list(subset_wires_tuple)\n","    dm = circuit_partial_density(arr, wires_list)\n","    return dm\n","\n","def partial_density_kernel(X, Y, subset_wires=[0,1], method=\"hilbert_schmidt\"):\n","    \"\"\"\n","    Projected kernel on a subset of qubits.\n","    For each x_i,y_j, we get partial density matrices => dm_x, dm_y.\n","    Then define kernel = Tr(dm_x dm_y) if method=\"hilbert_schmidt\"\n","    (One can define other overlaps, e.g. Uhlmann fidelity, but we do simpler HS.)\n","    \"\"\"\n","    X = np.atleast_2d(X)\n","    Y = np.atleast_2d(Y)\n","    N, dx = X.shape\n","    M, dx2 = Y.shape\n","    assert dx==dx2, \"Dimension mismatch\"\n","\n","    # Turn subset_wires into a tuple so it can be used in a cache key\n","    wires_tuple = tuple(subset_wires)\n","    K = np.zeros((N,M), dtype=float)\n","    for i in range(N):\n","        x_tuple = tuple(X[i])\n","        dm_x = get_partial_density(x_tuple, wires_tuple)\n","        for j in range(M):\n","            y_tuple = tuple(Y[j])\n","            dm_y = get_partial_density(y_tuple, wires_tuple)\n","            if method==\"hilbert_schmidt\":\n","                # HS overlap = Tr(dm_x dm_y)\n","                # dm_x, dm_y are pnp arrays => convert to np\n","                val = np.real(np.trace(dm_x @ dm_y))\n","                K[i,j]=val\n","            else:\n","                raise ValueError(\"Only 'hilbert_schmidt' method is implemented.\")\n","    return K\n","\n","##############################################################################\n","# 5) Basic Bayesian Optimization with random candidate sampling + EI\n","##############################################################################\n","def expected_improvement(X_star, f_best, gp):\n","    mu, std = gp.predict(X_star, return_std=True)\n","    ei = np.zeros_like(mu)\n","    mask = std>1e-12\n","    z = (f_best - mu[mask]) / std[mask]\n","    pdf = 1./np.sqrt(2.*math.pi)*np.exp(-0.5*z**2)\n","    cdf = 0.5*(1.+erf(z/np.sqrt(2.)))\n","    improvement = (f_best - mu[mask])*cdf + std[mask]*pdf\n","    improvement = np.maximum(improvement, 0.)\n","    ei[mask]=improvement\n","    return ei\n","\n","def bo_with_partial_kernel(\n","    n_init=5,\n","    n_iter=20,\n","    n_cand=100,\n","    seed=0,\n","    dim = 7\n","):\n","    np.random.seed(seed)\n","    # init data\n","    X_data = np.random.rand(n_init, D)*2.*math.pi\n","    y_data = np.array([cost_fn(x) for x in X_data])\n","    # build kernel\n","    def kernel_fn1(X, Y):\n","        return partial_density_kernel(X, Y, subset_wires=[0], method=\"hilbert_schmidt\")\n","    def kernel_fn2(X, Y):\n","        return partial_density_kernel(X, Y, subset_wires=[1], method=\"hilbert_schmidt\") + partial_density_kernel(X, Y, subset_wires=[0], method=\"hilbert_schmidt\")\n","    def kernel_fn3(X, Y):\n","        return partial_density_kernel(X, Y, subset_wires=[2], method=\"hilbert_schmidt\") + partial_density_kernel(X, Y, subset_wires=[1], method=\"hilbert_schmidt\") + partial_density_kernel(X, Y, subset_wires=[0], method=\"hilbert_schmidt\")\n","    def kernel_fn4(X, Y):\n","        return partial_density_kernel(X, Y, subset_wires=[0,1], method=\"hilbert_schmidt\")\n","    def kernel_fn5(X, Y):\n","        return partial_density_kernel(X, Y, subset_wires=[1,2], method=\"hilbert_schmidt\") + partial_density_kernel(X, Y, subset_wires=[0,1], method=\"hilbert_schmidt\")\n","    def kernel_fn6(X, Y):\n","        return partial_density_kernel(X, Y, subset_wires=[0,2], method=\"hilbert_schmidt\") + partial_density_kernel(X, Y, subset_wires=[1,2], method=\"hilbert_schmidt\") + partial_density_kernel(X, Y, subset_wires=[0,1], method=\"hilbert_schmidt\")\n","    def kernel_fn7(X, Y):\n","        return partial_density_kernel(X, Y, subset_wires=[0,1,2], method=\"hilbert_schmidt\")\n","\n","    kernels = [kernel_fn1,kernel_fn2,kernel_fn3,kernel_fn4,kernel_fn5,kernel_fn6,kernel_fn7]\n","\n","    gp = GaussianProcessRegressor(kernel=kernels[dim-1], alpha=1e-8)\n","    gp.fit(X_data, y_data)\n","\n","    best_hist=[y_data.min()]\n","    for step in range(n_iter):\n","        f_best = y_data.min()\n","        X_cand = np.random.rand(n_cand, D)*2.*math.pi\n","        ei_vals=expected_improvement(X_cand, f_best, gp)\n","        idx=np.argmax(ei_vals)\n","        x_next=X_cand[idx]\n","        y_next=cost_fn(x_next)\n","\n","        X_data = np.vstack([X_data, x_next])\n","        y_data = np.concatenate([y_data, [y_next]])\n","        gp.fit(X_data, y_data)\n","        best_so_far=min(best_hist[-1], y_next)\n","        best_hist.append(best_so_far)\n","        #print(f\"Iteration {step+1:2d}, best so far = {best_so_far:.6f}\")\n","    return X_data, y_data, best_hist\n","\n","##############################################################################\n","# 6) Run\n","##############################################################################\n","if __name__==\"__main__\":\n","    # Example usage: define partial kernel on qubits [0,2]\n","    # Then do BO\n","\n","    trials = 10\n","    energy_final = []\n","    energy_final_std = []\n","\n","    for dim in range(1,8):\n","        energies = []\n","        for trial in range(trials):\n","            X_data, y_data, best_hist = bo_with_partial_kernel(\n","                n_init=3,\n","                n_iter=100,\n","                n_cand=100,\n","                seed=None,\n","                dim = dim\n","            )\n","            energies.append(best_hist)\n","            print(f\"dim {dim} completed trial {trial}\")\n","            print(\"Final best energy found:\", best_hist[-1])\n","        energy_all = np.array(energies)\n","        avg_energy = energy_all.mean(axis=0)\n","        std_energy = energy_all.std(axis=0)\n","\n","        energy_final.append(avg_energy[-1])\n","        energy_final_std.append(std_energy[-1])\n","        print(avg_energy[-1],std_energy[-1])\n","\n","\n","\n","    plt.errorbar(np.array([1,2,3,4,5,6,7]), np.array(energy_final), np.array(energy_final_std), ls=\"-\",\n","                marker='d',\n","                color=\"#009E73\",\n","                alpha=1.0,\n","                capsize=4)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xfMgnZLiOjHr"},"outputs":[],"source":["##############################################################################\n","# 1) Imports & Setup\n","##############################################################################\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","from functools import lru_cache\n","from scipy.special import erf\n","\n","import pennylane as qml\n","from pennylane import numpy as pnp\n","\n","##############################################################################\n","# 2) GaussianProcessRegressor (unchanged from your prompt)\n","##############################################################################\n","class GaussianProcessRegressor:\n","    \"\"\"\n","    Gaussian Process Regressor for d-dimensional inputs.\n","    Returns both predictive mean and std if requested.\n","    \"\"\"\n","    def __init__(self, kernel, alpha=1e-5):\n","        self.kernel = kernel\n","        self.alpha = alpha\n","        self.X_train = None\n","        self.y_train = None\n","        self.K_inv = None\n","\n","    def fit(self, X, y):\n","        X = np.array(X)\n","        y = np.array(y)\n","        self.X_train = X\n","        self.y_train = y\n","        K = self.kernel(X, X)\n","        K += self.alpha * np.eye(len(X))\n","        self.K_inv = np.linalg.inv(K)\n","\n","    def predict(self, X_test, return_std=False):\n","        X_test = np.array(X_test)\n","        K_star = self.kernel(X_test, self.X_train)\n","        y_mean = K_star @ (self.K_inv @ self.y_train)\n","\n","        if return_std:\n","            K_star_star = self.kernel(X_test, X_test)\n","            cov = K_star_star - K_star @ self.K_inv @ K_star.T\n","            var = np.diag(cov)\n","            var = np.maximum(var, 0.0)\n","            y_std = np.sqrt(var)\n","            return y_mean, y_std\n","        else:\n","            return y_mean\n","\n","##############################################################################\n","# 3) Setup: 3-qubit circuit, Ising Hamiltonian, cost function\n","##############################################################################\n","num_qubits = 3\n","num_layers = 1\n","dev = qml.device(\"default.qubit\", wires=num_qubits, shots=None)\n","\n","# Build H = sum_j X_jX_{j+1} + sum_j Z_j\n","obs = []\n","coeffs = []\n","for j in range(num_qubits-1):\n","    obs.append(qml.PauliX(j) @ qml.PauliX(j+1))\n","    coeffs.append(1.0)\n","for j in range(num_qubits):\n","    obs.append(qml.PauliZ(j))\n","    coeffs.append(1.0)\n","H = qml.Hamiltonian(coeffs, obs)\n","\n","# dimension => (2 + 2*num_layers)*num_qubits => 24 if num_layers=3,\n","# but here we set num_layers=1 for a simpler example => (2+2*1)*3=6 parameters\n","D = (2 + 2*num_layers)*num_qubits\n","\n","@qml.qnode(dev)\n","def circuit_energy(params_flat):\n","    \"\"\"\n","    Prepare the circuit (with 'num_layers'=1) and measure expectation of H.\n","    \"\"\"a\n","    params_reshaped = params_flat.reshape((2*(num_layers+1), num_qubits))\n","    # 1) initial block\n","    for q in range(num_qubits):\n","        qml.RY(params_reshaped[0,q], wires=q)\n","        qml.RZ(params_reshaped[1,q], wires=q)\n","    idx=2\n","    # repeated layers\n","    for _layer in range(num_layers):\n","        qml.CNOT(wires=[0,1])\n","        qml.CNOT(wires=[0,2])\n","        qml.CNOT(wires=[1,2])\n","        for q in range(num_qubits):\n","            qml.RY(params_reshaped[idx,q], wires=q)\n","            qml.RZ(params_reshaped[idx+1,q], wires=q)\n","        idx+=2\n","    return qml.expval(H)\n","\n","def cost_fn(params_flat):\n","    return float(circuit_energy(params_flat))\n","\n","##############################################################################\n","# 4) Partial-Density QNode => measure subset of qubits' density matrix\n","##############################################################################\n","# We'll specify `subset_wires` as a list of qubit indices. Then we do\n","# qml.density_matrix(subset_wires). This returns a 2^(|subset|) x 2^(|subset|) complex matrix,\n","# which might be mixed if the global state is partially traced out.\n","\n","@qml.qnode(dev)\n","def circuit_partial_density(params_flat, subset_wires):\n","    \"\"\"\n","    Returns the partial density matrix for a specified subset of qubits.\n","    The rest are traced out automatically by PennyLane.\n","    \"\"\"\n","    # same circuit as above\n","    params_reshaped = params_flat.reshape((2*(num_layers+1), num_qubits))\n","    # initial\n","    for q in range(num_qubits):\n","        qml.RY(params_reshaped[0,q], wires=q)\n","        qml.RZ(params_reshaped[1,q], wires=q)\n","    idx=2\n","    for _layer in range(num_layers):\n","        qml.CNOT(wires=[0,1])\n","        qml.CNOT(wires=[0,2])\n","        qml.CNOT(wires=[1,2])\n","        for q in range(num_qubits):\n","            qml.RY(params_reshaped[idx,q], wires=q)\n","            qml.RZ(params_reshaped[idx+1,q], wires=q)\n","        idx+=2\n","\n","    return qml.density_matrix(wires=subset_wires)\n","\n","@lru_cache(None)\n","def get_partial_density(params_tuple, subset_wires_tuple):\n","    \"\"\"\n","    Cache for partial density matrix.\n","    PennyLane expects a python list for `wires=...`,\n","    but we can't store a list as a cache key, so we use a tuple of int.\n","    \"\"\"\n","    arr = pnp.array(params_tuple, dtype=pnp.float64)\n","    # convert subset_wires_tuple back to a list\n","    wires_list = list(subset_wires_tuple)\n","    dm = circuit_partial_density(arr, wires_list)\n","    return dm\n","\n","def partial_density_kernel(X, Y, subset_wires=[0,1], method=\"hilbert_schmidt\"):\n","    \"\"\"\n","    Projected kernel on a subset of qubits.\n","    For each x_i,y_j, we get partial density matrices => dm_x, dm_y.\n","    Then define kernel = Tr(dm_x dm_y) if method=\"hilbert_schmidt\"\n","    (One can define other overlaps, e.g. Uhlmann fidelity, but we do simpler HS.)\n","    \"\"\"\n","    X = np.atleast_2d(X)\n","    Y = np.atleast_2d(Y)\n","    N, dx = X.shape\n","    M, dx2 = Y.shape\n","    assert dx==dx2, \"Dimension mismatch\"\n","\n","    # Turn subset_wires into a tuple so it can be used in a cache key\n","    wires_tuple = tuple(subset_wires)\n","    K = np.zeros((N,M), dtype=float)\n","    for i in range(N):\n","        x_tuple = tuple(X[i])\n","        dm_x = get_partial_density(x_tuple, wires_tuple)\n","        for j in range(M):\n","            y_tuple = tuple(Y[j])\n","            dm_y = get_partial_density(y_tuple, wires_tuple)\n","            if method==\"hilbert_schmidt\":\n","                # HS overlap = Tr(dm_x dm_y)\n","                # dm_x, dm_y are pnp arrays => convert to np\n","                val = np.real(np.trace(dm_x @ dm_y))\n","                K[i,j]=val\n","            else:\n","                raise ValueError(\"Only 'hilbert_schmidt' method is implemented.\")\n","    return K\n","\n","##############################################################################\n","# 5) Basic Bayesian Optimization with random candidate sampling + EI\n","##############################################################################\n","def expected_improvement(X_star, f_best, gp):\n","    mu, std = gp.predict(X_star, return_std=True)\n","    ei = np.zeros_like(mu)\n","    mask = std>1e-12\n","    z = (f_best - mu[mask]) / std[mask]\n","    pdf = 1./np.sqrt(2.*math.pi)*np.exp(-0.5*z**2)\n","    cdf = 0.5*(1.+erf(z/np.sqrt(2.)))\n","    improvement = (f_best - mu[mask])*cdf + std[mask]*pdf\n","    improvement = np.maximum(improvement, 0.)\n","    ei[mask]=improvement\n","    return ei\n","\n","def bo_with_partial_kernel(\n","    n_init=5,\n","    n_iter=20,\n","    n_cand=100,\n","    seed=0,\n","    dim = 7\n","):\n","    np.random.seed(seed)\n","    # init data\n","    X_data = np.random.rand(n_init, D)*2.*math.pi\n","    y_data = np.array([cost_fn(x) for x in X_data])\n","    # build kernel\n","    def kernel_fn1(X, Y):\n","        return partial_density_kernel(X, Y, subset_wires=[0], method=\"hilbert_schmidt\")\n","    def kernel_fn2(X, Y):\n","        return partial_density_kernel(X, Y, subset_wires=[1], method=\"hilbert_schmidt\") + partial_density_kernel(X, Y, subset_wires=[0], method=\"hilbert_schmidt\")\n","    def kernel_fn3(X, Y):\n","        return partial_density_kernel(X, Y, subset_wires=[2], method=\"hilbert_schmidt\") + partial_density_kernel(X, Y, subset_wires=[1], method=\"hilbert_schmidt\") + partial_density_kernel(X, Y, subset_wires=[0], method=\"hilbert_schmidt\")\n","    def kernel_fn4(X, Y):\n","        return partial_density_kernel(X, Y, subset_wires=[0,1], method=\"hilbert_schmidt\")\n","    def kernel_fn5(X, Y):\n","        return partial_density_kernel(X, Y, subset_wires=[1,2], method=\"hilbert_schmidt\") + partial_density_kernel(X, Y, subset_wires=[0,1], method=\"hilbert_schmidt\")\n","    def kernel_fn6(X, Y):\n","        return partial_density_kernel(X, Y, subset_wires=[0,2], method=\"hilbert_schmidt\") + partial_density_kernel(X, Y, subset_wires=[1,2], method=\"hilbert_schmidt\") + partial_density_kernel(X, Y, subset_wires=[0,1], method=\"hilbert_schmidt\")\n","    def kernel_fn7(X, Y):\n","        return partial_density_kernel(X, Y, subset_wires=[0,1,2], method=\"hilbert_schmidt\")\n","\n","    kernels = [kernel_fn1,kernel_fn2,kernel_fn3,kernel_fn4,kernel_fn5,kernel_fn6,kernel_fn7]\n","\n","    gp = GaussianProcessRegressor(kernel=kernels[dim-1], alpha=1e-8)\n","    gp.fit(X_data, y_data)\n","\n","    best_hist=[y_data.min()]\n","    for step in range(n_iter):\n","        f_best = y_data.min()\n","        X_cand = np.random.rand(n_cand, D)*2.*math.pi\n","        ei_vals=expected_improvement(X_cand, f_best, gp)\n","        idx=np.argmax(ei_vals)\n","        x_next=X_cand[idx]\n","        y_next=cost_fn(x_next)\n","\n","        X_data = np.vstack([X_data, x_next])\n","        y_data = np.concatenate([y_data, [y_next]])\n","        gp.fit(X_data, y_data)\n","        best_so_far=min(best_hist[-1], y_next)\n","        best_hist.append(best_so_far)\n","        #print(f\"Iteration {step+1:2d}, best so far = {best_so_far:.6f}\")\n","    return X_data, y_data, best_hist\n","\n","##############################################################################\n","# 6) Run\n","##############################################################################\n","if __name__==\"__main__\":\n","    # Example usage: define partial kernel on qubits [0,2]\n","    # Then do BO\n","\n","    trials = 10\n","    energy_final = []\n","    energy_final_std = []\n","\n","    for dim in range(1,8):\n","        energies = []\n","        for trial in range(trials):\n","            X_data, y_data, best_hist = bo_with_partial_kernel(\n","                n_init=3,\n","                n_iter=100,\n","                n_cand=100,\n","                seed=None,\n","                dim = dim\n","            )\n","            energies.append(best_hist)\n","            print(f\"dim {dim} completed trial {trial}\")\n","            print(\"Final best energy found:\", best_hist[-1])\n","        energy_all = np.array(energies)\n","        avg_energy = energy_all.mean(axis=0)\n","        std_energy = energy_all.std(axis=0)\n","\n","        energy_final.append(avg_energy[-1])\n","        energy_final_std.append(std_energy[-1])\n","        print(avg_energy[-1],std_energy[-1])\n","\n","\n","\n","    plt.errorbar(np.array([1,2,3,4,5,6,7]), np.array(energy_final), np.array(energy_final_std), ls=\"-\",\n","                marker='d',\n","                color=\"#009E73\",\n","                alpha=1.0,\n","                capsize=4)\n"]},{"cell_type":"markdown","metadata":{"id":"4ql30DbvXlHF"},"source":["# GP with LFGBS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XDVELGea06H1"},"outputs":[],"source":["##############################################################################\n","# Imports\n","##############################################################################\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","from functools import lru_cache\n","from scipy.optimize import minimize\n","from scipy.special import erf\n","\n","import pennylane as qml\n","from pennylane import numpy as pnp\n","\n","##############################################################################\n","# 1) The same GaussianProcessRegressor class from your prompt\n","##############################################################################\n","class GaussianProcessRegressor:\n","    \"\"\"\n","    Gaussian Process Regressor for d-dimensional inputs.\n","    Returns both predictive mean and std if requested.\n","    \"\"\"\n","    def __init__(self, kernel, alpha=1e-5):\n","        self.kernel = kernel\n","        self.alpha = alpha\n","        self.X_train = None\n","        self.y_train = None\n","        self.K_inv = None\n","\n","    def fit(self, X, y):\n","        X = np.array(X)\n","        y = np.array(y)\n","        self.X_train = X\n","        self.y_train = y\n","        K = self.kernel(X, X)\n","        K += self.alpha * np.eye(len(X))\n","        self.K_inv = np.linalg.inv(K)\n","\n","    def predict(self, X_test, return_std=False):\n","        X_test = np.array(X_test)\n","        K_star = self.kernel(X_test, self.X_train)\n","        y_mean = K_star @ (self.K_inv @ self.y_train)\n","\n","        if return_std:\n","            K_star_star = self.kernel(X_test, X_test)\n","            cov = K_star_star - K_star @ self.K_inv @ K_star.T\n","            var = np.diag(cov)\n","            var = np.maximum(var, 0.0)\n","            y_std = np.sqrt(var)\n","            return y_mean, y_std\n","        else:\n","            return y_mean\n","\n","##############################################################################\n","# 2) Define 3-qubit circuit (24 params) + cost function\n","##############################################################################\n","num_qubits = 3\n","num_layers = 1\n","D = (2 + 2*num_layers)*num_qubits  # 24\n","dev = qml.device(\"default.qubit\", wires=num_qubits, shots=None)\n","\n","obs = []\n","coeffs = []\n","# Coupling X_j X_{j+1}\n","for j in range(num_qubits - 1):\n","    obs.append(qml.PauliX(j) @ qml.PauliX(j+1))\n","    coeffs.append(1.0)\n","# Local Z\n","for j in range(num_qubits):\n","    obs.append(qml.PauliZ(j))\n","    coeffs.append(1.0)\n","\n","H = qml.Hamiltonian(coeffs, obs)\n","\n","@qml.qnode(dev)\n","def circuit_energy(params):\n","    params_reshaped = params.reshape((2*(num_layers+1), num_qubits))\n","    # initial block\n","    for q in range(num_qubits):\n","        qml.RY(params_reshaped[0,q], wires=q)\n","        qml.RZ(params_reshaped[1,q], wires=q)\n","    idx=2\n","    for _layer in range(num_layers):\n","        qml.CNOT(wires=[0,1])\n","        qml.CNOT(wires=[0,2])\n","        qml.CNOT(wires=[1,2])\n","        for q in range(num_qubits):\n","            qml.RY(params_reshaped[idx,q], wires=q)\n","            qml.RZ(params_reshaped[idx+1,q], wires=q)\n","        idx+=2\n","    return qml.expval(H)\n","\n","def cost_fn(params):\n","    return float(circuit_energy(params))\n","\n","##############################################################################\n","# 3) Quantum Fidelity Kernel (Same as previous \"fidelity\" approach)\n","##############################################################################\n","@qml.qnode(dev)\n","def circuit_state(params):\n","    \"\"\"\n","    Return state vector from same circuit. We'll cache it for fidelity calcs.\n","    \"\"\"\n","    params_reshaped = params.reshape((2*(num_layers+1), num_qubits))\n","    # same arrangement\n","    for q in range(num_qubits):\n","        qml.RY(params_reshaped[0,q], wires=q)\n","        qml.RZ(params_reshaped[1,q], wires=q)\n","    idx=2\n","    for _layer in range(num_layers):\n","        qml.CNOT(wires=[0,1])\n","        qml.CNOT(wires=[0,2])\n","        qml.CNOT(wires=[1,2])\n","        for q in range(num_qubits):\n","            qml.RY(params_reshaped[idx,q], wires=q)\n","            qml.RZ(params_reshaped[idx+1,q], wires=q)\n","        idx+=2\n","    return qml.state()\n","\n","@lru_cache(None)\n","def get_cached_state(params_tuple):\n","    arr = pnp.array(params_tuple, dtype=pnp.float64)\n","    return circuit_state(arr)\n","\n","def quantum_fidelity_kernel(X, Y):\n","    X = np.atleast_2d(X)\n","    Y = np.atleast_2d(Y)\n","    N, D_ = X.shape\n","    M, D2_ = Y.shape\n","    assert D_==D2_, \"Dimension mismatch\"\n","    K = np.zeros((N,M), dtype=float)\n","    for i in range(N):\n","        xi_tuple = tuple(X[i])\n","        psi_i = get_cached_state(xi_tuple)\n","        for j in range(M):\n","            yj_tuple = tuple(Y[j])\n","            psi_j = get_cached_state(yj_tuple)\n","            overlap = np.vdot(psi_i, psi_j)\n","            val = abs(overlap)**2\n","            K[i,j]=val\n","    return K\n","\n","##############################################################################\n","# 4) Implement a standard EI function (like in Bayesian Opt).\n","#    We'll do a naive negative-EI for LBFGS, so we'll define:\n","##############################################################################\n","def gp_ei(x, f_best, gp):\n","    \"\"\"\n","    Return negative-EI for the point x, so we can do minimization => we want to\n","    minimize -EI => maximize EI\n","    \"\"\"\n","    # x shape => (D,)\n","    x = x[None,:]  # shape(1,D)\n","    mu, std = gp.predict(x, return_std=True)\n","    mu, std = mu[0], std[0]\n","    eps=1e-12\n","    if std<eps:\n","        return 0.0  # or -0 => no improvement\n","    z=(f_best - mu)/std\n","    pdf=1./np.sqrt(2.*math.pi)*math.exp(-0.5*z**2)\n","    cdf=0.5*(1.+erf(z/np.sqrt(2.)))\n","    improvement = (f_best - mu)*cdf + std*pdf\n","    if improvement<0.0:\n","        improvement=0.0\n","    return -improvement  # negative => we'll do minimize\n","\n","def gp_ei_grad(x, f_best, gp):\n","    \"\"\"\n","    We'll do naive finite difference gradient for shape(D,).\n","    x => shape(D,)\n","    We'll do step=1e-4 or so => partial derivative of gp_ei w.r.t x[d].\n","    This is an example. It's possibly expensive for D=24 but demonstrates the approach.\n","    \"\"\"\n","    grad = np.zeros_like(x)\n","    fx = gp_ei(x, f_best, gp)\n","    step=1e-4\n","    for d in range(len(x)):\n","        old_val = x[d]\n","        x[d] = old_val+step\n","        fplus = gp_ei(x, f_best, gp)\n","        x[d] = old_val\n","        grad[d] = (fplus - fx)/step\n","    return grad\n","\n","##############################################################################\n","# 5) The iterative Bayesian Optimization approach with L-BFGS to refine candidate\n","##############################################################################\n","def bo_with_lbfgs(\n","    kernel_fn=quantum_fidelity_kernel,\n","    n_init=5,\n","    n_iter=15,\n","    seed=0,\n","    n_cand=1000\n","):\n","    np.random.seed(seed)\n","    # 1) gather initial data\n","    X_data = np.random.rand(n_init, D)*2.*math.pi\n","    y_data = np.array([cost_fn(row) for row in X_data])\n","\n","    gp = GaussianProcessRegressor(kernel=kernel_fn, alpha=1e-9)\n","    gp.fit(X_data, y_data)\n","\n","    best_hist=[y_data.min()]\n","\n","    for step in range(n_iter):\n","        # f_best\n","        f_best = y_data.min()\n","        # 2) do small random search => pick best from 1000\n","        X_cand = np.random.rand(n_cand, D)*2.*math.pi\n","        ei_vals=[]\n","        for row in X_cand:\n","            ei_vals.append(-gp_ei(row, f_best, gp))  # we store negativeEI to see how large\n","        ei_vals=np.array(ei_vals)\n","        idx=np.argmax(ei_vals) # min of negative => max of EI\n","        x0 = X_cand[idx].copy()\n","\n","        # 3) run LBFGS from x0 to refine\n","        def fun_and_grad(z):\n","            val = gp_ei(z, f_best, gp)\n","            g = gp_ei_grad(z, f_best, gp)\n","            return val, g\n","        bounds=[(0.,2.*math.pi)]*D\n","        res = minimize(fun_and_grad, x0, method='L-BFGS-B', jac=True, bounds=bounds,\n","                       options={'maxiter':30})\n","        x_next=res.x\n","        y_next=cost_fn(x_next)\n","\n","        # 4) update GP\n","        X_data = np.vstack([X_data, x_next])\n","        y_data = np.concatenate([y_data, [y_next]])\n","        gp.fit(X_data, y_data)\n","\n","        current_best=min(best_hist[-1], y_next)\n","        best_hist.append(current_best)\n","        print(f\"Iteration {step+1:2d}, best so far = {current_best:.6f}, y_next={y_next:.6f}\")\n","\n","    return X_data, y_data, best_hist\n","\n","##############################################################################\n","# 6) Run\n","##############################################################################\n","if __name__==\"__main__\":\n","\n","\n","    Xd, yd, bhist = bo_with_lbfgs(kernel_fn=quantum_fidelity_kernel,\n","                                  n_init=5,\n","                                  n_iter=200,\n","                                  seed=None,\n","                                  n_cand=200)\n","    print(\"Final best energy found:\", bhist[-1])\n","    plt.plot(bhist, label=\"Best so far\")\n","    plt.xlabel(\"Iteration\")\n","    plt.ylabel(\"Energy\")\n","    plt.title(\"BO with Quantum Fidelity Kernel + LBFGS Refinement\")\n","    plt.legend()\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l5iF3CZQu3pF"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"C0vcuY9Au344"},"source":["# GP LFBGS with different kernel, Final Experiment for running"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"82ZzU9Qlu3-E"},"outputs":[],"source":["##############################################################################\n","# Imports\n","##############################################################################\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","from functools import lru_cache\n","from scipy.optimize import minimize\n","from scipy.special import erf\n","\n","import pennylane as qml\n","from pennylane import numpy as pnp\n","\n","##############################################################################\n","# 1) GaussianProcessRegressor (unchanged)\n","##############################################################################\n","class GaussianProcessRegressor:\n","    \"\"\"\n","    Gaussian Process Regressor for d-dimensional inputs.\n","    Returns both predictive mean and std if requested.\n","    \"\"\"\n","    def __init__(self, kernel, alpha=1e-5):\n","        self.kernel = kernel\n","        self.alpha = alpha\n","        self.X_train = None\n","        self.y_train = None\n","        self.K_inv = None\n","\n","    def fit(self, X, y):\n","        X = np.array(X)\n","        y = np.array(y)\n","        self.X_train = X\n","        self.y_train = y\n","        K = self.kernel(X, X)\n","        K += self.alpha * np.eye(len(X))\n","        self.K_inv = np.linalg.inv(K)\n","\n","    def predict(self, X_test, return_std=False):\n","        X_test = np.array(X_test)\n","        K_star = self.kernel(X_test, self.X_train)\n","        y_mean = K_star @ (self.K_inv @ self.y_train)\n","\n","        if return_std:\n","            K_star_star = self.kernel(X_test, X_test)\n","            cov = K_star_star - K_star @ self.K_inv @ K_star.T\n","            var = np.diag(cov)\n","            var = np.maximum(var, 0.0)\n","            y_std = np.sqrt(var)\n","            return y_mean, y_std\n","        else:\n","            return y_mean\n","\n","##############################################################################\n","# 2) Define 3-qubit circuit (24 params) + cost function\n","#    (Use num_layers=3 => D=24)\n","##############################################################################\n","num_qubits = 3\n","num_layers = 5\n","D = (2 + 2*num_layers)*num_qubits  # => (2+2*3)*3=8*3=24\n","dev = qml.device(\"default.qubit\", wires=num_qubits, shots=None)\n","\n","##############################################################################\n","# Build the Ising Hamiltonian: sum_j X_j X_{j+1} + sum_j Z_j\n","##############################################################################\n","obs = []\n","coeffs = []\n","# Coupling X_j X_{j+1}\n","for j in range(num_qubits - 1):\n","    obs.append(qml.PauliX(j) @ qml.PauliX(j+1))\n","    coeffs.append(1.0)\n","# Local Z\n","for j in range(num_qubits):\n","    obs.append(qml.PauliZ(j))\n","    coeffs.append(1.0)\n","\n","H = qml.Hamiltonian(coeffs, obs)\n","\n","@qml.qnode(dev)\n","def circuit_energy(params):\n","    \"\"\"\n","    Prepare a 3-qubit circuit with num_layers=3 => 24 parameters.\n","    Return expectation of H.\n","    \"\"\"\n","    params_reshaped = params.reshape((2*(num_layers+1), num_qubits))\n","    # initial block\n","    for q in range(num_qubits):\n","        qml.RY(params_reshaped[0, q], wires=q)\n","        qml.RZ(params_reshaped[1, q], wires=q)\n","\n","    idx = 2\n","    for _layer in range(num_layers):\n","        # Entangling\n","        qml.CNOT(wires=[0, 1])\n","        qml.CNOT(wires=[0, 2])\n","        qml.CNOT(wires=[1, 2])\n","        # Single-qubit rotations\n","        for q in range(num_qubits):\n","            qml.RY(params_reshaped[idx, q], wires=q)\n","            qml.RZ(params_reshaped[idx+1, q], wires=q)\n","        idx += 2\n","\n","    return qml.expval(H)\n","\n","def cost_fn(params):\n","    return float(circuit_energy(params))\n","\n","##############################################################################\n","# 3) Partial-density QNode + partial_density_kernel\n","##############################################################################\n","@qml.qnode(dev)\n","def circuit_partial_density(params, subset_wires):\n","    \"\"\"\n","    Returns the partial density matrix for a specified subset of qubits.\n","    The rest are traced out automatically by PennyLane.\n","    \"\"\"\n","    params_reshaped = params.reshape((2*(num_layers+1), num_qubits))\n","    # same circuit\n","    for q in range(num_qubits):\n","        qml.RY(params_reshaped[0, q], wires=q)\n","        qml.RZ(params_reshaped[1, q], wires=q)\n","    idx = 2\n","    for _layer in range(num_layers):\n","        qml.CNOT(wires=[0,1])\n","        qml.CNOT(wires=[0,2])\n","        qml.CNOT(wires=[1,2])\n","        for q in range(num_qubits):\n","            qml.RY(params_reshaped[idx, q], wires=q)\n","            qml.RZ(params_reshaped[idx+1, q], wires=q)\n","        idx += 2\n","\n","    return qml.density_matrix(wires=subset_wires)\n","\n","@lru_cache(None)\n","def get_partial_density(params_tuple, subset_wires_tuple):\n","    \"\"\"\n","    Cached partial density matrix.\n","    \"\"\"\n","    arr = pnp.array(params_tuple, dtype=pnp.float64)\n","    dm = circuit_partial_density(arr, list(subset_wires_tuple))\n","    return dm\n","\n","def partial_density_kernel(X, Y, subset_wires=[0], method=\"hilbert_schmidt\"):\n","    \"\"\"\n","    Projected kernel on specified subset of qubits.\n","    For each x_i,y_j => partial density matrices => dm_x, dm_y => Tr(dm_x dm_y).\n","    \"\"\"\n","    X = np.atleast_2d(X)\n","    Y = np.atleast_2d(Y)\n","    N, dx = X.shape\n","    M, dx2 = Y.shape\n","    assert dx == dx2, \"Dimension mismatch\"\n","\n","    wires_tuple = tuple(subset_wires)\n","    K = np.zeros((N, M), dtype=float)\n","\n","    for i in range(N):\n","        x_tuple = tuple(X[i])\n","        dm_x = get_partial_density(x_tuple, wires_tuple)\n","        for j in range(M):\n","            y_tuple = tuple(Y[j])\n","            dm_y = get_partial_density(y_tuple, wires_tuple)\n","            # Hilbert-Schmidt => Tr(dm_x dm_y)\n","            val = np.real(np.trace(dm_x @ dm_y))\n","            K[i, j] = val\n","    return K\n","\n","##############################################################################\n","# 4) We'll define multiple partial kernels for demonstration\n","##############################################################################\n","def kernel_fn1(X, Y):\n","    # single-qubit overlap on qubit 0\n","    return partial_density_kernel(X, Y, subset_wires=[0], method=\"hilbert_schmidt\")\n","\n","def kernel_fn2(X, Y):\n","    # sum of partial overlaps on qubits 0 and 1\n","    return partial_density_kernel(X, Y, subset_wires=[0]) + \\\n","           partial_density_kernel(X, Y, subset_wires=[1])\n","\n","def kernel_fn3(X, Y):\n","    # sum of partial overlaps on qubits 0,1,2 separately\n","    return (partial_density_kernel(X, Y, subset_wires=[0]) +\n","            partial_density_kernel(X, Y, subset_wires=[1]) +\n","            partial_density_kernel(X, Y, subset_wires=[2]))\n","\n","def kernel_fn4(X, Y):\n","    # partial overlap on subset [0,1]\n","    return partial_density_kernel(X, Y, subset_wires=[0,1])\n","\n","def kernel_fn5(X, Y):\n","    return (partial_density_kernel(X, Y, subset_wires=[0,1]) +\n","            partial_density_kernel(X, Y, subset_wires=[1,2]))\n","\n","def kernel_fn6(X, Y):\n","    return (partial_density_kernel(X, Y, subset_wires=[0,1]) +\n","            partial_density_kernel(X, Y, subset_wires=[1,2]) +\n","            partial_density_kernel(X, Y, subset_wires=[0,2]))\n","\n","def kernel_fn7(X, Y):\n","    # full (no partial trace) => subset_wires=[0,1,2]\n","    return partial_density_kernel(X, Y, subset_wires=[0,1,2])\n","\n","KERNELS = [kernel_fn1, kernel_fn2, kernel_fn3, kernel_fn4, kernel_fn5, kernel_fn6, kernel_fn7]\n","\n","##############################################################################\n","# 5) Define EI + gradient for LBFGS (from second snippet, unchanged logic)\n","##############################################################################\n","def gp_ei(x, f_best, gp):\n","    \"\"\"\n","    Return negative-EI for the point x => we do 'minimize' =>\n","    so negative-EI is what we minimize to find maximum of EI.\n","    \"\"\"\n","    x = x[None, :]  # shape (1,D)\n","    mu, std = gp.predict(x, return_std=True)\n","    mu, std = mu[0], std[0]\n","    eps = 1e-12\n","    if std < eps:\n","        # No improvement if variance is tiny\n","        return 0.0\n","    z = (f_best - mu)/std\n","    pdf = 1./np.sqrt(2.*math.pi)*math.exp(-0.5*z**2)\n","    cdf = 0.5*(1.+erf(z/np.sqrt(2.)))\n","    improvement = (f_best - mu)*cdf + std*pdf\n","    if improvement < 0.0:\n","        improvement = 0.0\n","    return -improvement  # negative => we'll do minimize\n","\n","def gp_ei_grad(x, f_best, gp):\n","    \"\"\"\n","    Naive finite-difference gradient for gp_ei.\n","    x => shape(D,)\n","    \"\"\"\n","    grad = np.zeros_like(x)\n","    fx = gp_ei(x, f_best, gp)\n","    step = 1e-4\n","    for d in range(len(x)):\n","        old_val = x[d]\n","        x[d] = old_val + step\n","        fplus = gp_ei(x, f_best, gp)\n","        x[d] = old_val\n","        grad[d] = (fplus - fx)/step\n","    return grad\n","\n","##############################################################################\n","# 6) bo_with_lbfgs => Main iterative routine that uses partial kernel\n","##############################################################################\n","def bo_with_lbfgs(\n","    kernel_fn,\n","    n_init=5,\n","    n_iter=50,\n","    seed=0,\n","    n_cand=100\n","):\n","    \"\"\"\n","    Perform Bayesian Optimization with a given kernel_fn,\n","    using L-BFGS to refine each new candidate.\n","    \"\"\"\n","    np.random.seed(seed)\n","    # 1) gather initial data\n","    X_data = np.random.rand(n_init, D)*2.*math.pi\n","    y_data = np.array([cost_fn(row) for row in X_data])\n","\n","    gp = GaussianProcessRegressor(kernel=kernel_fn, alpha=1e-9)\n","    gp.fit(X_data, y_data)\n","\n","    best_hist = [y_data.min()]\n","\n","    for step in range(n_iter):\n","        # current best\n","        f_best = y_data.min()\n","        # 2) do random search => pick best among n_cand\n","        X_cand = np.random.rand(n_cand, D)*2.*math.pi\n","        ei_vals = []\n","        for row in X_cand:\n","            # store negativeEI => we want largest positive EI\n","            ei_vals.append(-gp_ei(row, f_best, gp))\n","        ei_vals = np.array(ei_vals)\n","        idx = np.argmax(ei_vals)\n","        x0 = X_cand[idx].copy()\n","\n","        # 3) refine with L-BFGS\n","        def fun_and_grad(z):\n","            val = gp_ei(z, f_best, gp)\n","            g = gp_ei_grad(z, f_best, gp)\n","            return val, g\n","\n","        bounds = [(0., 2.*math.pi)]*D\n","        res = minimize(fun_and_grad, x0, method='L-BFGS-B',\n","                       jac=True, bounds=bounds,\n","                       options={'maxiter': 30})\n","\n","        x_next = res.x\n","        y_next = cost_fn(x_next)\n","\n","        # 4) update GP\n","        X_data = np.vstack([X_data, x_next])\n","        y_data = np.concatenate([y_data, [y_next]])\n","        gp.fit(X_data, y_data)\n","\n","        current_best = min(best_hist[-1], y_next)\n","        best_hist.append(current_best)\n","        print(f\"Iteration {step+1:2d}, best so far = {current_best:.6f}, y_next={y_next:.6f}\")\n","\n","    return X_data, y_data, best_hist\n","\n","##############################################################################\n","# 7) Example Usage\n","##############################################################################\n","# if __name__==\"__main__\":\n","#     # Example: pick any partial kernel, e.g. kernel_fn4 => subset_wires=[0,1]\n","#     # Or pick among KERNELS = [kernel_fn1,...,kernel_fn7].\n","#     # We'll do a small run for demonstration.\n","\n","#     kernel_choice = kernel_fn7  # partial density on [0,1]\n","#     X_data, y_data, best_hist = bo_with_lbfgs(\n","#         kernel_fn=kernel_choice,\n","#         n_init=5,\n","#         n_iter=30,\n","#         seed=None,\n","#         n_cand=10\n","#     )\n","#     print(\"Final best energy found:\", best_hist[-1])\n","\n","#     # Plot\n","#     plt.plot(best_hist, label=\"Best so far\")\n","#     plt.xlabel(\"Iteration\")\n","#     plt.ylabel(\"Energy\")\n","#     plt.title(\"BO with Partial-Density Kernel + LBFGS (subset [0,1])\")\n","#     plt.legend()\n","#     plt.show()\n","\n","#     # If you want to loop over all partial kernels, you could do:\n","#     # for i, kfn in enumerate(KERNELS):\n","#     #     Xd, yd, bh = bo_with_lbfgs(kfn, n_init=3, n_iter=15, seed=42)\n","#     #     print(f\"Kernel #{i+1}: final best energy = {bh[-1]}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bSWjis352LW4"},"outputs":[],"source":["if __name__==\"__main__\":\n","    # Example usage: define partial kernel on qubits [0,2]\n","    # Then do BO\n","\n","    trials = 30\n","    energy_final = []\n","    energy_final_std = []\n","\n","    for dim in range(7):\n","        energies = []\n","        for trial in range(trials):\n","            X_data, y_data, best_hist = bo_with_lbfgs(\n","                kernel_fn=KERNELS[dim],\n","                n_init=5,\n","                n_iter=50,\n","                seed=None,\n","                n_cand=10\n","            )\n","            energies.append(best_hist)\n","            print(f\"dim {dim} completed trial {trial}\")\n","            print(\"Final best energy found:\", best_hist[-1])\n","        energy_all = np.array(energies)\n","        avg_energy = energy_all.mean(axis=0)\n","        std_energy = energy_all.std(axis=0)\n","\n","        energy_final.append(avg_energy[-1])\n","        energy_final_std.append(std_energy[-1])\n","        print(avg_energy[-1],std_energy[-1])\n","\n","\n","\n","    plt.errorbar(np.array([1,2,3,4,5,6,7]), np.array(energy_final), np.array(energy_final_std), ls=\"-\",\n","                marker='d',\n","                color=\"#009E73\",\n","                alpha=1.0,\n","                capsize=4)"]}],"metadata":{"colab":{"collapsed_sections":["Xe15VI0eXqSk","4ql30DbvXlHF"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}